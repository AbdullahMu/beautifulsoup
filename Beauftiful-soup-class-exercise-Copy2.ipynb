{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Introduction to Beautiful Soup (Class Exercise)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Utilize Beautiful Soup to extract information from HTML \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Beautiful Soup?\n",
    "---\n",
    "\n",
    "- It is a popular Python library for web scraping (parse the HTML).\n",
    "\n",
    "#### Install Beautiful Soup\n",
    "\n",
    "Students will need to install Selenium using one of the following:\n",
    "- **Anaconda:** `conda install -c anaconda beautifulsoup4`\n",
    "- **pip:** `pip install beautifulsoup4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Web scraping steps :\n",
    "\n",
    "## Step 1 : Download Html page \n",
    "## Step 2 : Parsing data (BS)\n",
    "## Step 3 : Save data in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 :\n",
    "---\n",
    "\n",
    "<img src=\"https://www.absolutegeeks.com/wp-content/uploads/2016/11/196945-souq-logo-secondary-en-web-f8e9a3-original-1456722541.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "<br>\n",
    "\n",
    "## Let's Scrape (Mobiles prices / Souq Saudi) headlines\n",
    "\n",
    "<br>\n",
    "Souq is a Middle East’s online marketplace. Let's take their [Mobile](https://saudi.souq.com/sa-en/apple/mobile-phones-33/new/a-t-c/s/?_=1459842493768&page=1&ref=nav) headlines using Python **requests**, and practice selecting various elements.\n",
    "\n",
    "Build a new dataframe as :\n",
    "\n",
    "|mobile_name|price|\n",
    "|---|---|\n",
    "|Apple iPhone 6S|1500|\n",
    "| ...|...|\n",
    "| ...|...|\n",
    "\n",
    "let's start by explore the structure of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1 : Download Html page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://saudi.souq.com/sa-en/apple/mobile-phones-33/new/a-t-c/s/?_=1459842493768&page=1&ref=nav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 :parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(response.text, 'lxml')  # build tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selector.xpath(exp)   ---> selector object\n",
    "<br>\n",
    "selector.xpath(exp).extract()   ---> string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soup.find()   -- > soup object\n",
    "<br>\n",
    "soup.find().text   -- > string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3 : Save data in dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'mobile_name': mobile_name_lst,\n",
    "                   'price': mobile_price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 :\n",
    "---\n",
    "\n",
    "<img src=\"https://production.hsobjects.com/assets/hunger_first/sociallogo-cd7264256ec8ec1c4bd13e7b7cd60d623ae6d190190413decaca55c565461b70.jpg\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "<br>\n",
    "\n",
    "## Let's Scrape (Restaurants Promotions  / Hunger Station) headlines\n",
    "\n",
    "<br>\n",
    "HungerStation is an online food ordering sites. Let's take their [restaurants promotions](https://hungerstation.com/ar/promotions) headlines using Python **requests**, and practice selecting various elements.\n",
    "\n",
    "Build a new dataframe as :\n",
    "\n",
    "|restaurant_name|promotion_description|\n",
    "|---|---|\n",
    "|زعتر و زيت|احصل على طلبك بدون رسوم توصيل|\n",
    "| ...|...|\n",
    "| ...|...|\n",
    "\n",
    "\n",
    "let's start by explore the structure of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1 : Download Html page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 :parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3 : Save data in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 : MEDIUM Blogs\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Let's Scrape (Number of Clabs, Name and Date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
